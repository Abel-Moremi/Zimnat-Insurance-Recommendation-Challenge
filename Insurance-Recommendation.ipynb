{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/Train.csv')\n",
    "test = pd.read_csv('Data/Test.csv')\n",
    "submission = pd.read_csv('Data/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_train_columns = train.columns\n",
    "c = 0\n",
    "for v in train.values:\n",
    "  info = v[:8]\n",
    "  binary = v[8:]\n",
    "  index = [k for k, i in enumerate(binary) if i == 1]\n",
    "  for i in index:\n",
    "    c+=1\n",
    "    for k in range(len(binary)):\n",
    "      if k == i:\n",
    "        binary_transformed = list(copy.copy(binary))\n",
    "        binary_transformed[i] = 0\n",
    "        X_train.append(list(info) + binary_transformed + [X_train_columns[8+k]] + [c])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'ID2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "true_values = []\n",
    "c = 0\n",
    "for v in test.values:\n",
    "  c += 1\n",
    "  info = v[:8]\n",
    "  binary = v[8:]\n",
    "  index = [k for k, i in enumerate(binary) if i == 1]\n",
    "  X_test.append(list(info) + list(binary) + [c])\n",
    "  for k in test.columns[8:][index]:\n",
    "    true_values.append(v[0] + ' X ' + k)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "       'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "       '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "       'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'ID2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = []\n",
    "features_test = []\n",
    "columns = []\n",
    "\n",
    "append_features = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n",
    "'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n",
    "'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n",
    "'birth_year']\n",
    "for v in append_features:\n",
    "  features_train.append(X_train[v].values.reshape(-1, 1))\n",
    "  features_test.append(X_test[v].values.reshape(-1, 1))\n",
    "  columns.append(np.array([v]))\n",
    "\n",
    "y_train = X_train[['product_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.concatenate(features_train, axis=1)\n",
    "features_test = np.concatenate(features_test, axis=1)\n",
    "columns = np.concatenate(np.array(columns))\n",
    "\n",
    "X_train = pd.DataFrame(features_train)\n",
    "X_train.columns = columns\n",
    "X_test = pd.DataFrame(features_test)\n",
    "X_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['date1'] = X_train['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_train['date2'] = X_train['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_train['date3'] = X_train['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_train.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_test['date1'] = X_test['join_date'].apply(lambda x: int(x.split('/')[0]) if (x == x) else np.nan)\n",
    "X_test['date2'] = X_test['join_date'].apply(lambda x: int(x.split('/')[1]) if (x == x) else np.nan)\n",
    "X_test['date3'] = X_test['join_date'].apply(lambda x: int(x.split('/')[2]) if (x == x) else np.nan)\n",
    "X_test.drop('join_date', axis=1, inplace=True)\n",
    "\n",
    "X_train['date_diff'] = X_train['date3'] - X_train['birth_year']\n",
    "X_test['date_diff'] = X_test['date3'] - X_test['birth_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "y_train = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data = X_train.append(X_test)\n",
    "for v in ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',]:\n",
    "  data.loc[:,v] = le.fit_transform(data.loc[:,v])\n",
    "X_train = data[:X_train.shape[0]]\n",
    "X_test = data[-X_test.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(y_train.iloc[:,0])\n",
    "y_train = pd.DataFrame(le.transform(y_train.iloc[:,0]))\n",
    "y_train.columns = ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.054559\n",
      "0:\tlearn: 2.3045876\ttotal: 4.28s\tremaining: 2h 22m 33s\n",
      "1:\tlearn: 2.0324586\ttotal: 8.02s\tremaining: 2h 13m 32s\n",
      "2:\tlearn: 1.8435748\ttotal: 12.8s\tremaining: 2h 22m 20s\n",
      "3:\tlearn: 1.7121058\ttotal: 15.5s\tremaining: 2h 9m 13s\n",
      "4:\tlearn: 1.5907272\ttotal: 20.1s\tremaining: 2h 13m 47s\n",
      "5:\tlearn: 1.4920917\ttotal: 24.4s\tremaining: 2h 14m 59s\n",
      "6:\tlearn: 1.4109468\ttotal: 28.2s\tremaining: 2h 13m 35s\n",
      "7:\tlearn: 1.3401344\ttotal: 32.1s\tremaining: 2h 13m 18s\n",
      "8:\tlearn: 1.2774178\ttotal: 35.8s\tremaining: 2h 11m 59s\n",
      "9:\tlearn: 1.2227315\ttotal: 39.6s\tremaining: 2h 11m 29s\n",
      "10:\tlearn: 1.1730231\ttotal: 44s\tremaining: 2h 12m 40s\n",
      "11:\tlearn: 1.1268018\ttotal: 47.8s\tremaining: 2h 11m 57s\n",
      "12:\tlearn: 1.0843030\ttotal: 51s\tremaining: 2h 9m 53s\n",
      "13:\tlearn: 1.0449043\ttotal: 54.3s\tremaining: 2h 8m 28s\n",
      "14:\tlearn: 1.0106200\ttotal: 57.7s\tremaining: 2h 7m 21s\n",
      "15:\tlearn: 0.9804906\ttotal: 1m 1s\tremaining: 2h 7m 23s\n",
      "16:\tlearn: 0.9508918\ttotal: 1m 5s\tremaining: 2h 7m 51s\n",
      "17:\tlearn: 0.9260242\ttotal: 1m 10s\tremaining: 2h 9m 26s\n",
      "18:\tlearn: 0.9010727\ttotal: 1m 14s\tremaining: 2h 8m 58s\n",
      "19:\tlearn: 0.8775661\ttotal: 1m 17s\tremaining: 2h 7m 51s\n",
      "20:\tlearn: 0.8553215\ttotal: 1m 21s\tremaining: 2h 7m 22s\n",
      "21:\tlearn: 0.8358755\ttotal: 1m 24s\tremaining: 2h 6m 39s\n",
      "22:\tlearn: 0.8181211\ttotal: 1m 28s\tremaining: 2h 6m 23s\n",
      "23:\tlearn: 0.8009816\ttotal: 1m 32s\tremaining: 2h 6m 16s\n",
      "24:\tlearn: 0.7848916\ttotal: 1m 37s\tremaining: 2h 8m 17s\n",
      "25:\tlearn: 0.7690722\ttotal: 1m 40s\tremaining: 2h 7m 38s\n",
      "26:\tlearn: 0.7564052\ttotal: 1m 44s\tremaining: 2h 7m 6s\n",
      "27:\tlearn: 0.7424667\ttotal: 1m 48s\tremaining: 2h 6m 51s\n",
      "28:\tlearn: 0.7301736\ttotal: 1m 52s\tremaining: 2h 6m 53s\n",
      "29:\tlearn: 0.7184992\ttotal: 1m 55s\tremaining: 2h 6m 37s\n",
      "30:\tlearn: 0.7082295\ttotal: 1m 59s\tremaining: 2h 6m 13s\n",
      "31:\tlearn: 0.6975193\ttotal: 2m 2s\tremaining: 2h 5m 31s\n",
      "32:\tlearn: 0.6883636\ttotal: 2m 5s\tremaining: 2h 5m 1s\n",
      "33:\tlearn: 0.6789531\ttotal: 2m 9s\tremaining: 2h 5m 6s\n",
      "34:\tlearn: 0.6698211\ttotal: 2m 13s\tremaining: 2h 4m 41s\n",
      "35:\tlearn: 0.6600300\ttotal: 2m 16s\tremaining: 2h 4m 21s\n",
      "36:\tlearn: 0.6522491\ttotal: 2m 21s\tremaining: 2h 4m 43s\n",
      "37:\tlearn: 0.6445001\ttotal: 2m 24s\tremaining: 2h 4m 23s\n",
      "38:\tlearn: 0.6377845\ttotal: 2m 29s\tremaining: 2h 5m 15s\n",
      "39:\tlearn: 0.6306105\ttotal: 2m 34s\tremaining: 2h 5m 50s\n",
      "40:\tlearn: 0.6241708\ttotal: 2m 39s\tremaining: 2h 6m 39s\n",
      "41:\tlearn: 0.6178652\ttotal: 2m 43s\tremaining: 2h 6m 52s\n",
      "42:\tlearn: 0.6119298\ttotal: 2m 48s\tremaining: 2h 7m 44s\n",
      "43:\tlearn: 0.6062021\ttotal: 2m 52s\tremaining: 2h 8m 9s\n",
      "44:\tlearn: 0.6010894\ttotal: 2m 57s\tremaining: 2h 8m 17s\n",
      "45:\tlearn: 0.5975197\ttotal: 3m 2s\tremaining: 2h 9m 2s\n",
      "46:\tlearn: 0.5925827\ttotal: 3m 6s\tremaining: 2h 8m 52s\n",
      "47:\tlearn: 0.5873771\ttotal: 3m 10s\tremaining: 2h 8m 54s\n",
      "48:\tlearn: 0.5820017\ttotal: 3m 14s\tremaining: 2h 9m 3s\n",
      "49:\tlearn: 0.5774981\ttotal: 3m 18s\tremaining: 2h 9m 3s\n",
      "50:\tlearn: 0.5734101\ttotal: 3m 23s\tremaining: 2h 9m 20s\n",
      "51:\tlearn: 0.5690578\ttotal: 3m 27s\tremaining: 2h 9m 47s\n",
      "52:\tlearn: 0.5653115\ttotal: 3m 32s\tremaining: 2h 10m 21s\n",
      "53:\tlearn: 0.5611534\ttotal: 3m 37s\tremaining: 2h 10m 35s\n",
      "54:\tlearn: 0.5573237\ttotal: 3m 42s\tremaining: 2h 10m 53s\n",
      "55:\tlearn: 0.5534068\ttotal: 3m 46s\tremaining: 2h 11m 8s\n",
      "56:\tlearn: 0.5501946\ttotal: 3m 51s\tremaining: 2h 11m 41s\n",
      "57:\tlearn: 0.5467550\ttotal: 3m 57s\tremaining: 2h 12m 22s\n",
      "58:\tlearn: 0.5438865\ttotal: 4m 2s\tremaining: 2h 13m 8s\n",
      "59:\tlearn: 0.5411266\ttotal: 4m 7s\tremaining: 2h 13m 24s\n",
      "60:\tlearn: 0.5381304\ttotal: 4m 12s\tremaining: 2h 13m 32s\n",
      "61:\tlearn: 0.5357212\ttotal: 4m 17s\tremaining: 2h 14m 4s\n",
      "62:\tlearn: 0.5329044\ttotal: 4m 21s\tremaining: 2h 14m\n",
      "63:\tlearn: 0.5310261\ttotal: 4m 26s\tremaining: 2h 14m 22s\n",
      "64:\tlearn: 0.5281768\ttotal: 4m 32s\tremaining: 2h 15m 3s\n",
      "65:\tlearn: 0.5259405\ttotal: 4m 37s\tremaining: 2h 15m 17s\n",
      "66:\tlearn: 0.5236770\ttotal: 4m 40s\tremaining: 2h 14m 58s\n",
      "67:\tlearn: 0.5212654\ttotal: 4m 45s\tremaining: 2h 15m 3s\n",
      "68:\tlearn: 0.5189095\ttotal: 4m 49s\tremaining: 2h 14m 53s\n",
      "69:\tlearn: 0.5167893\ttotal: 4m 53s\tremaining: 2h 15m 4s\n",
      "70:\tlearn: 0.5146516\ttotal: 4m 57s\tremaining: 2h 14m 53s\n",
      "71:\tlearn: 0.5127186\ttotal: 5m 2s\tremaining: 2h 14m 55s\n",
      "72:\tlearn: 0.5107484\ttotal: 5m 6s\tremaining: 2h 15m 3s\n",
      "73:\tlearn: 0.5086073\ttotal: 5m 10s\tremaining: 2h 14m 50s\n",
      "74:\tlearn: 0.5063673\ttotal: 5m 14s\tremaining: 2h 14m 42s\n",
      "75:\tlearn: 0.5046157\ttotal: 5m 18s\tremaining: 2h 14m 28s\n",
      "76:\tlearn: 0.5028466\ttotal: 5m 22s\tremaining: 2h 14m 24s\n",
      "77:\tlearn: 0.5012297\ttotal: 5m 26s\tremaining: 2h 14m 9s\n",
      "78:\tlearn: 0.4995014\ttotal: 5m 31s\tremaining: 2h 14m 15s\n",
      "79:\tlearn: 0.4979378\ttotal: 5m 34s\tremaining: 2h 13m 51s\n",
      "80:\tlearn: 0.4966045\ttotal: 5m 39s\tremaining: 2h 14m 11s\n",
      "81:\tlearn: 0.4951986\ttotal: 5m 45s\tremaining: 2h 14m 29s\n",
      "82:\tlearn: 0.4939852\ttotal: 5m 51s\tremaining: 2h 15m 8s\n",
      "83:\tlearn: 0.4919363\ttotal: 5m 55s\tremaining: 2h 15m 15s\n",
      "84:\tlearn: 0.4901637\ttotal: 6m\tremaining: 2h 15m 20s\n",
      "85:\tlearn: 0.4884330\ttotal: 6m 5s\tremaining: 2h 15m 39s\n",
      "86:\tlearn: 0.4869664\ttotal: 6m 11s\tremaining: 2h 16m 8s\n",
      "87:\tlearn: 0.4856016\ttotal: 6m 16s\tremaining: 2h 16m 24s\n",
      "88:\tlearn: 0.4843663\ttotal: 6m 22s\tremaining: 2h 16m 46s\n",
      "89:\tlearn: 0.4827543\ttotal: 6m 27s\tremaining: 2h 17m 8s\n",
      "90:\tlearn: 0.4815223\ttotal: 6m 32s\tremaining: 2h 17m 16s\n",
      "91:\tlearn: 0.4806052\ttotal: 6m 37s\tremaining: 2h 17m 32s\n",
      "92:\tlearn: 0.4793138\ttotal: 6m 42s\tremaining: 2h 17m 41s\n",
      "93:\tlearn: 0.4783967\ttotal: 6m 48s\tremaining: 2h 17m 55s\n",
      "94:\tlearn: 0.4777265\ttotal: 6m 53s\tremaining: 2h 18m 6s\n",
      "95:\tlearn: 0.4766574\ttotal: 6m 58s\tremaining: 2h 18m 15s\n",
      "96:\tlearn: 0.4756852\ttotal: 7m 3s\tremaining: 2h 18m 26s\n",
      "97:\tlearn: 0.4744092\ttotal: 7m 7s\tremaining: 2h 18m 22s\n",
      "98:\tlearn: 0.4733562\ttotal: 7m 13s\tremaining: 2h 18m 43s\n",
      "99:\tlearn: 0.4723572\ttotal: 7m 18s\tremaining: 2h 18m 45s\n",
      "100:\tlearn: 0.4707285\ttotal: 7m 24s\tremaining: 2h 19m 17s\n",
      "101:\tlearn: 0.4697585\ttotal: 7m 29s\tremaining: 2h 19m 29s\n",
      "102:\tlearn: 0.4688003\ttotal: 7m 34s\tremaining: 2h 19m 27s\n",
      "103:\tlearn: 0.4681824\ttotal: 7m 40s\tremaining: 2h 19m 53s\n",
      "104:\tlearn: 0.4673233\ttotal: 7m 45s\tremaining: 2h 20m 9s\n",
      "105:\tlearn: 0.4663325\ttotal: 7m 51s\tremaining: 2h 20m 24s\n",
      "106:\tlearn: 0.4652943\ttotal: 7m 56s\tremaining: 2h 20m 34s\n",
      "107:\tlearn: 0.4645033\ttotal: 8m 2s\tremaining: 2h 20m 52s\n",
      "108:\tlearn: 0.4631449\ttotal: 8m 6s\tremaining: 2h 20m 41s\n",
      "109:\tlearn: 0.4626993\ttotal: 8m 12s\tremaining: 2h 21m 1s\n",
      "110:\tlearn: 0.4617287\ttotal: 8m 18s\tremaining: 2h 21m 15s\n",
      "111:\tlearn: 0.4607787\ttotal: 8m 23s\tremaining: 2h 21m 35s\n",
      "112:\tlearn: 0.4600775\ttotal: 8m 29s\tremaining: 2h 21m 47s\n",
      "113:\tlearn: 0.4590121\ttotal: 8m 34s\tremaining: 2h 21m 58s\n",
      "114:\tlearn: 0.4585006\ttotal: 8m 40s\tremaining: 2h 22m 8s\n",
      "115:\tlearn: 0.4576664\ttotal: 8m 45s\tremaining: 2h 22m 11s\n",
      "116:\tlearn: 0.4567633\ttotal: 8m 50s\tremaining: 2h 22m 23s\n",
      "117:\tlearn: 0.4561796\ttotal: 8m 56s\tremaining: 2h 22m 33s\n",
      "118:\tlearn: 0.4556718\ttotal: 9m 2s\tremaining: 2h 22m 57s\n",
      "119:\tlearn: 0.4550875\ttotal: 9m 7s\tremaining: 2h 23m 4s\n",
      "120:\tlearn: 0.4544492\ttotal: 9m 12s\tremaining: 2h 23m 4s\n",
      "121:\tlearn: 0.4538818\ttotal: 9m 17s\tremaining: 2h 22m 58s\n",
      "122:\tlearn: 0.4532558\ttotal: 9m 21s\tremaining: 2h 22m 49s\n",
      "123:\tlearn: 0.4525344\ttotal: 9m 26s\tremaining: 2h 22m 52s\n",
      "124:\tlearn: 0.4517962\ttotal: 9m 30s\tremaining: 2h 22m 39s\n",
      "125:\tlearn: 0.4509256\ttotal: 9m 34s\tremaining: 2h 22m 22s\n",
      "126:\tlearn: 0.4503702\ttotal: 9m 38s\tremaining: 2h 22m 8s\n",
      "127:\tlearn: 0.4499360\ttotal: 9m 43s\tremaining: 2h 22m 8s\n",
      "128:\tlearn: 0.4493506\ttotal: 9m 48s\tremaining: 2h 22m 8s\n",
      "129:\tlearn: 0.4488286\ttotal: 9m 52s\tremaining: 2h 22m 9s\n",
      "130:\tlearn: 0.4481617\ttotal: 9m 57s\tremaining: 2h 22m 2s\n",
      "131:\tlearn: 0.4476416\ttotal: 10m 2s\tremaining: 2h 22m 5s\n",
      "132:\tlearn: 0.4469053\ttotal: 10m 7s\tremaining: 2h 22m 1s\n",
      "133:\tlearn: 0.4463166\ttotal: 10m 12s\tremaining: 2h 22m 8s\n",
      "134:\tlearn: 0.4461224\ttotal: 10m 18s\tremaining: 2h 22m 23s\n",
      "135:\tlearn: 0.4455532\ttotal: 10m 23s\tremaining: 2h 22m 29s\n",
      "136:\tlearn: 0.4448865\ttotal: 10m 28s\tremaining: 2h 22m 29s\n",
      "137:\tlearn: 0.4444030\ttotal: 10m 32s\tremaining: 2h 22m 15s\n",
      "138:\tlearn: 0.4438863\ttotal: 10m 36s\tremaining: 2h 22m 6s\n",
      "139:\tlearn: 0.4435398\ttotal: 10m 40s\tremaining: 2h 21m 49s\n",
      "140:\tlearn: 0.4430108\ttotal: 10m 44s\tremaining: 2h 21m 41s\n",
      "141:\tlearn: 0.4423937\ttotal: 10m 50s\tremaining: 2h 21m 46s\n",
      "142:\tlearn: 0.4417042\ttotal: 10m 54s\tremaining: 2h 21m 42s\n",
      "143:\tlearn: 0.4414801\ttotal: 10m 59s\tremaining: 2h 21m 42s\n",
      "144:\tlearn: 0.4407882\ttotal: 11m 4s\tremaining: 2h 21m 37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145:\tlearn: 0.4404635\ttotal: 11m 9s\tremaining: 2h 21m 43s\n",
      "146:\tlearn: 0.4400884\ttotal: 11m 14s\tremaining: 2h 21m 44s\n",
      "147:\tlearn: 0.4399542\ttotal: 11m 20s\tremaining: 2h 21m 50s\n",
      "148:\tlearn: 0.4392280\ttotal: 11m 24s\tremaining: 2h 21m 46s\n",
      "149:\tlearn: 0.4384105\ttotal: 11m 28s\tremaining: 2h 21m 28s\n",
      "150:\tlearn: 0.4375344\ttotal: 11m 32s\tremaining: 2h 21m 17s\n",
      "151:\tlearn: 0.4366661\ttotal: 11m 36s\tremaining: 2h 21m 5s\n",
      "152:\tlearn: 0.4360923\ttotal: 11m 40s\tremaining: 2h 21m\n",
      "153:\tlearn: 0.4356064\ttotal: 11m 46s\tremaining: 2h 21m 4s\n",
      "154:\tlearn: 0.4352912\ttotal: 11m 51s\tremaining: 2h 21m 3s\n",
      "155:\tlearn: 0.4349360\ttotal: 11m 56s\tremaining: 2h 21m 5s\n",
      "156:\tlearn: 0.4346473\ttotal: 12m 1s\tremaining: 2h 21m 5s\n",
      "157:\tlearn: 0.4341978\ttotal: 12m 6s\tremaining: 2h 21m 11s\n",
      "158:\tlearn: 0.4338346\ttotal: 12m 11s\tremaining: 2h 21m 14s\n",
      "159:\tlearn: 0.4334461\ttotal: 12m 15s\tremaining: 2h 21m\n",
      "160:\tlearn: 0.4327345\ttotal: 12m 20s\tremaining: 2h 20m 54s\n",
      "161:\tlearn: 0.4323253\ttotal: 12m 24s\tremaining: 2h 20m 48s\n",
      "162:\tlearn: 0.4318465\ttotal: 12m 28s\tremaining: 2h 20m 34s\n",
      "163:\tlearn: 0.4313375\ttotal: 12m 32s\tremaining: 2h 20m 23s\n",
      "164:\tlearn: 0.4307272\ttotal: 12m 36s\tremaining: 2h 20m 12s\n",
      "165:\tlearn: 0.4302790\ttotal: 12m 40s\tremaining: 2h 19m 57s\n",
      "166:\tlearn: 0.4298427\ttotal: 12m 44s\tremaining: 2h 19m 47s\n",
      "167:\tlearn: 0.4295315\ttotal: 12m 48s\tremaining: 2h 19m 39s\n",
      "168:\tlearn: 0.4290326\ttotal: 12m 52s\tremaining: 2h 19m 28s\n",
      "169:\tlearn: 0.4289276\ttotal: 12m 56s\tremaining: 2h 19m 22s\n",
      "170:\tlearn: 0.4287207\ttotal: 13m 1s\tremaining: 2h 19m 20s\n",
      "171:\tlearn: 0.4281874\ttotal: 13m 6s\tremaining: 2h 19m 17s\n",
      "172:\tlearn: 0.4280170\ttotal: 13m 12s\tremaining: 2h 19m 25s\n",
      "173:\tlearn: 0.4272336\ttotal: 13m 15s\tremaining: 2h 19m 12s\n",
      "174:\tlearn: 0.4265374\ttotal: 13m 20s\tremaining: 2h 19m 5s\n",
      "175:\tlearn: 0.4263219\ttotal: 13m 25s\tremaining: 2h 19m 6s\n",
      "176:\tlearn: 0.4261211\ttotal: 13m 29s\tremaining: 2h 18m 58s\n",
      "177:\tlearn: 0.4259419\ttotal: 13m 34s\tremaining: 2h 18m 55s\n",
      "178:\tlearn: 0.4256876\ttotal: 13m 38s\tremaining: 2h 18m 48s\n",
      "179:\tlearn: 0.4251215\ttotal: 13m 43s\tremaining: 2h 18m 43s\n",
      "180:\tlearn: 0.4242930\ttotal: 13m 47s\tremaining: 2h 18m 32s\n",
      "181:\tlearn: 0.4240302\ttotal: 13m 51s\tremaining: 2h 18m 28s\n",
      "182:\tlearn: 0.4235815\ttotal: 13m 55s\tremaining: 2h 18m 13s\n",
      "183:\tlearn: 0.4230714\ttotal: 13m 59s\tremaining: 2h 18m 7s\n",
      "184:\tlearn: 0.4227197\ttotal: 14m 4s\tremaining: 2h 18m 4s\n",
      "185:\tlearn: 0.4225946\ttotal: 14m 9s\tremaining: 2h 18m 6s\n",
      "186:\tlearn: 0.4223373\ttotal: 14m 13s\tremaining: 2h 17m 59s\n",
      "187:\tlearn: 0.4220432\ttotal: 14m 18s\tremaining: 2h 17m 59s\n",
      "188:\tlearn: 0.4216914\ttotal: 14m 24s\tremaining: 2h 18m\n",
      "189:\tlearn: 0.4210130\ttotal: 14m 28s\tremaining: 2h 17m 52s\n",
      "190:\tlearn: 0.4208273\ttotal: 14m 33s\tremaining: 2h 17m 54s\n",
      "191:\tlearn: 0.4206931\ttotal: 14m 37s\tremaining: 2h 17m 44s\n",
      "192:\tlearn: 0.4203175\ttotal: 14m 42s\tremaining: 2h 17m 39s\n",
      "193:\tlearn: 0.4199939\ttotal: 14m 46s\tremaining: 2h 17m 33s\n",
      "194:\tlearn: 0.4196964\ttotal: 14m 51s\tremaining: 2h 17m 31s\n",
      "195:\tlearn: 0.4192097\ttotal: 14m 55s\tremaining: 2h 17m 23s\n",
      "196:\tlearn: 0.4186682\ttotal: 14m 59s\tremaining: 2h 17m 10s\n",
      "197:\tlearn: 0.4184433\ttotal: 15m 3s\tremaining: 2h 16m 59s\n",
      "198:\tlearn: 0.4177053\ttotal: 15m 7s\tremaining: 2h 16m 54s\n",
      "199:\tlearn: 0.4174683\ttotal: 15m 12s\tremaining: 2h 16m 49s\n",
      "200:\tlearn: 0.4168578\ttotal: 15m 15s\tremaining: 2h 16m 35s\n",
      "201:\tlearn: 0.4161732\ttotal: 15m 19s\tremaining: 2h 16m 23s\n",
      "202:\tlearn: 0.4158288\ttotal: 15m 23s\tremaining: 2h 16m 18s\n",
      "203:\tlearn: 0.4151800\ttotal: 15m 26s\tremaining: 2h 16m 1s\n",
      "204:\tlearn: 0.4149688\ttotal: 15m 30s\tremaining: 2h 15m 48s\n",
      "205:\tlearn: 0.4145544\ttotal: 15m 34s\tremaining: 2h 15m 39s\n",
      "206:\tlearn: 0.4142917\ttotal: 15m 38s\tremaining: 2h 15m 32s\n",
      "207:\tlearn: 0.4140654\ttotal: 15m 42s\tremaining: 2h 15m 23s\n",
      "208:\tlearn: 0.4137787\ttotal: 15m 46s\tremaining: 2h 15m 14s\n",
      "209:\tlearn: 0.4133032\ttotal: 15m 50s\tremaining: 2h 15m 1s\n",
      "210:\tlearn: 0.4131102\ttotal: 15m 54s\tremaining: 2h 14m 56s\n",
      "211:\tlearn: 0.4126499\ttotal: 15m 59s\tremaining: 2h 14m 48s\n",
      "212:\tlearn: 0.4121884\ttotal: 16m 2s\tremaining: 2h 14m 37s\n",
      "213:\tlearn: 0.4118279\ttotal: 16m 7s\tremaining: 2h 14m 32s\n",
      "214:\tlearn: 0.4111291\ttotal: 16m 10s\tremaining: 2h 14m 17s\n",
      "215:\tlearn: 0.4107153\ttotal: 16m 14s\tremaining: 2h 14m 9s\n",
      "216:\tlearn: 0.4103619\ttotal: 16m 18s\tremaining: 2h 14m 1s\n",
      "217:\tlearn: 0.4099490\ttotal: 16m 22s\tremaining: 2h 13m 55s\n",
      "218:\tlearn: 0.4095991\ttotal: 16m 27s\tremaining: 2h 13m 50s\n",
      "219:\tlearn: 0.4092194\ttotal: 16m 31s\tremaining: 2h 13m 40s\n",
      "220:\tlearn: 0.4088480\ttotal: 16m 34s\tremaining: 2h 13m 27s\n",
      "221:\tlearn: 0.4082950\ttotal: 16m 38s\tremaining: 2h 13m 14s\n",
      "222:\tlearn: 0.4078866\ttotal: 16m 41s\tremaining: 2h 13m 2s\n",
      "223:\tlearn: 0.4075960\ttotal: 16m 45s\tremaining: 2h 12m 52s\n",
      "224:\tlearn: 0.4072719\ttotal: 16m 48s\tremaining: 2h 12m 39s\n",
      "225:\tlearn: 0.4071247\ttotal: 16m 53s\tremaining: 2h 12m 36s\n",
      "226:\tlearn: 0.4068269\ttotal: 16m 57s\tremaining: 2h 12m 26s\n",
      "227:\tlearn: 0.4063780\ttotal: 17m\tremaining: 2h 12m 13s\n",
      "228:\tlearn: 0.4058948\ttotal: 17m 5s\tremaining: 2h 12m 7s\n",
      "229:\tlearn: 0.4057173\ttotal: 17m 9s\tremaining: 2h 12m 5s\n",
      "230:\tlearn: 0.4055843\ttotal: 17m 15s\tremaining: 2h 12m 6s\n",
      "231:\tlearn: 0.4051686\ttotal: 17m 19s\tremaining: 2h 12m 1s\n",
      "232:\tlearn: 0.4045822\ttotal: 17m 22s\tremaining: 2h 11m 47s\n",
      "233:\tlearn: 0.4038509\ttotal: 17m 26s\tremaining: 2h 11m 40s\n",
      "234:\tlearn: 0.4034355\ttotal: 17m 31s\tremaining: 2h 11m 34s\n",
      "235:\tlearn: 0.4031568\ttotal: 17m 34s\tremaining: 2h 11m 23s\n",
      "236:\tlearn: 0.4026049\ttotal: 17m 37s\tremaining: 2h 11m 10s\n",
      "237:\tlearn: 0.4021442\ttotal: 17m 42s\tremaining: 2h 11m 4s\n",
      "238:\tlearn: 0.4014445\ttotal: 17m 45s\tremaining: 2h 10m 50s\n",
      "239:\tlearn: 0.4012674\ttotal: 17m 50s\tremaining: 2h 10m 49s\n",
      "240:\tlearn: 0.4010614\ttotal: 17m 54s\tremaining: 2h 10m 46s\n",
      "241:\tlearn: 0.4007432\ttotal: 17m 59s\tremaining: 2h 10m 42s\n",
      "242:\tlearn: 0.4005698\ttotal: 18m 4s\tremaining: 2h 10m 39s\n",
      "243:\tlearn: 0.4003585\ttotal: 18m 8s\tremaining: 2h 10m 33s\n",
      "244:\tlearn: 0.3998791\ttotal: 18m 12s\tremaining: 2h 10m 26s\n",
      "245:\tlearn: 0.3996760\ttotal: 18m 17s\tremaining: 2h 10m 25s\n",
      "246:\tlearn: 0.3993853\ttotal: 18m 20s\tremaining: 2h 10m 12s\n",
      "247:\tlearn: 0.3989634\ttotal: 18m 25s\tremaining: 2h 10m 6s\n",
      "248:\tlearn: 0.3986954\ttotal: 18m 28s\tremaining: 2h 9m 53s\n",
      "249:\tlearn: 0.3984138\ttotal: 18m 31s\tremaining: 2h 9m 42s\n",
      "250:\tlearn: 0.3978301\ttotal: 18m 35s\tremaining: 2h 9m 35s\n",
      "251:\tlearn: 0.3975633\ttotal: 18m 40s\tremaining: 2h 9m 29s\n",
      "252:\tlearn: 0.3974842\ttotal: 18m 44s\tremaining: 2h 9m 26s\n",
      "253:\tlearn: 0.3972067\ttotal: 18m 48s\tremaining: 2h 9m 20s\n",
      "254:\tlearn: 0.3969969\ttotal: 18m 54s\tremaining: 2h 9m 25s\n",
      "255:\tlearn: 0.3968040\ttotal: 18m 59s\tremaining: 2h 9m 24s\n",
      "256:\tlearn: 0.3962637\ttotal: 19m 3s\tremaining: 2h 9m 15s\n",
      "257:\tlearn: 0.3961022\ttotal: 19m 8s\tremaining: 2h 9m 14s\n",
      "258:\tlearn: 0.3955583\ttotal: 19m 12s\tremaining: 2h 9m 8s\n",
      "259:\tlearn: 0.3953652\ttotal: 19m 17s\tremaining: 2h 9m 5s\n",
      "260:\tlearn: 0.3950203\ttotal: 19m 21s\tremaining: 2h 9m 1s\n",
      "261:\tlearn: 0.3947229\ttotal: 19m 25s\tremaining: 2h 8m 51s\n",
      "262:\tlearn: 0.3944702\ttotal: 19m 30s\tremaining: 2h 8m 49s\n",
      "263:\tlearn: 0.3942779\ttotal: 19m 34s\tremaining: 2h 8m 44s\n",
      "264:\tlearn: 0.3940697\ttotal: 19m 38s\tremaining: 2h 8m 36s\n",
      "265:\tlearn: 0.3939781\ttotal: 19m 42s\tremaining: 2h 8m 31s\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=2000)\n",
    "model.fit(X_train.drop(columns=['ID', 'ID2']), y_train, cat_features=['sex','marital_status','branch_code','occupation_code','occupation_category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = model.predict_proba(X_test.drop(columns=['ID','ID2'], axis=1))\n",
    "y_test = pd.DataFrame(proba)\n",
    "print(y_test.columns)\n",
    "y_test.columns = le.inverse_transform(y_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.columns)\n",
    "answer_mass = []\n",
    "for i in range(X_test.shape[0]):\n",
    "  id = X_test['ID'].iloc[i]\n",
    "  for c in y_test.columns:\n",
    "    answer_mass.append([id + ' X ' + str(c), y_test[c].iloc[i]])\n",
    "    \n",
    "\n",
    "df_answer = pd.DataFrame(answer_mass)\n",
    "df_answer.columns = ['ID X PCODE', 'Label']\n",
    "for i in range(df_answer.shape[0]):\n",
    "  if df_answer['ID X PCODE'].iloc[i] in true_values:\n",
    "    df_answer['Label'].iloc[i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer.reset_index(drop=True, inplace=True)\n",
    "df_answer.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
